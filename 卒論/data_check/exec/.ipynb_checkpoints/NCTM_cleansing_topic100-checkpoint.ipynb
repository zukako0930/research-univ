{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#dictionary型に変換する関数\n",
    "def two_list_to_dict(key_list, val_list):\n",
    "      return dict(zip(key_list, val_list))\n",
    "\n",
    "#csvを読み込んで行ごとに分割\n",
    "def read_file(filename):\n",
    "    with open(str(filename),'r',encoding='utf8') as fbrand:\n",
    "        txt=fbrand.read() \n",
    "        lines = txt.split(\"\\n\")\n",
    "        return lines\n",
    "\n",
    "#csvの各行を分割してコーデごとのブランドlistのlistを作る.\n",
    "def make_Coordinate(lines):\n",
    "    Coordinate=[]\n",
    "    #重複のない辞書にするためにsetを用いる\n",
    "    s=set()\n",
    "    for line in lines:\n",
    "        brands=line.split(\",\")\n",
    "        Coordinate.append(brands)\n",
    "    return Coordinate\n",
    "\n",
    "#good_tagsのみに絞る\n",
    "def make_goodtags(lines,good_tags_set):\n",
    "    good_tags_list=[]\n",
    "    #重複のない辞書にするためにsetを用いる\n",
    "    s=set()\n",
    "    s=good_tags_set\n",
    "    for line in lines:\n",
    "        tags=line.split(\",\")\n",
    "        good_tags=[t for t in tags if t in s] \n",
    "        #if len(good_tags) == 0:\n",
    "        good_tags_list.append(good_tags)\n",
    "    return good_tags_list\n",
    "\n",
    "def make_brandset(lines):\n",
    "    #重複のない辞書にするためにsetを用いる\n",
    "        s=set()\n",
    "        for line in lines:\n",
    "            brands=line.split(\",\")\n",
    "            for brand in brands:\n",
    "                s.add(brand)\n",
    "        brand_set=list(s)\n",
    "        print(len(brand_set))\n",
    "        return brand_set\n",
    "\n",
    "def make_dict(brandset):\n",
    "    #dictionaryのindex\n",
    "    index=[]\n",
    "    for i in range(len(brandset)):\n",
    "        index.append(i)\n",
    "    #辞書\n",
    "    brand_dict=two_list_to_dict(brandset,index)\n",
    "    return brand_dict\n",
    "\n",
    "def brand_to_dictnum(Coordinates,brand_dict):\n",
    "    W = [] # words\n",
    "    #ブランドと補助情報の文書ごとのリストを作る\n",
    "    for Coordinate in Coordinates:\n",
    "    #list()をつけない場合iterator objectが帰ってくる\n",
    "        W.append(list(map(lambda v:brand_dict[v],Coordinate)))\n",
    "    return W\n",
    "\n",
    "#結果に関する関数  \n",
    "def brand_to_topic(Coordinates,nctm_Z): #nctm.Zはnctm.fitの結果が入っている\n",
    "    brand_topic=[]\n",
    "    for brands, Topics in zip(Coordinates,nctm_Z):\n",
    "        for brand,Topic in zip(brands,Topics):\n",
    "            pair=[brand,Topic]\n",
    "            brand_topic.append(pair)\n",
    "    return brand_topic\n",
    "\n",
    "def brand_topic_list_f(brand_topic,K):\n",
    "    brand_topic_list=[]\n",
    "    for i in range(K):\n",
    "        aaa=[x for x in brand_topic if x[1] == i]\n",
    "        #print(aaa)\n",
    "        brand_topic_list.append(aaa)\n",
    "    return brand_topic_list\n",
    "\n",
    "def t_setlist_brand_f(brand_topic_list,K):\n",
    "    #brandについて\n",
    "    t_setlist_brand=[] #各トピックごとのbrandのsetを代入するリスト\n",
    "    for i in range(K): #各トピックで回す\n",
    "        a=[] #各トピックでsetを作るためのローカル変数\n",
    "        for item in brand_topic_list[i]:\n",
    "            a.append(item[0])\n",
    "        a=set(a) #セットにする\n",
    "        a=list(a) #リストに直す\n",
    "        t_setlist_brand.append(a) #現在のトピックのsetをグローバルのリストに追加\n",
    "    #print(t_setlist[0]) \n",
    "    return t_setlist_brand\n",
    "\n",
    "def count_topic_f(brand_topic_list,t_setlist_brand,K):\n",
    "    count_topic=[] #全トピックの出現回数リストのリスト\n",
    "    for i in range(K): #トピックループ\n",
    "        count=np.zeros((len(t_setlist_brand[i]))) #今見ているトピックのsetの長さ分のbrandカウント配列を初期化\n",
    "        for item in brand_topic_list[i]: #itemはリスト\n",
    "            count[t_setlist_brand[i].index(item[0])]+=1 #今見ているbrandのインデックスをカウントアップ\n",
    "        count_topic.append(count) #一つのトピックについて見終えたらグローバルに追加\n",
    "    return count_topic\n",
    "\n",
    "def write_result(filename,t_setlist_brand,count_topic):\n",
    "    topic_num=0\n",
    "    for item,count in zip(t_setlist_brand,count_topic):\n",
    "        tuples=[]\n",
    "        for b,c in zip(item,count):\n",
    "            tuples.append(tuple((b,c)))\n",
    "        tuples.sort(key=lambda x:x[1],reverse=True) #x[1]に出現回数が入っているので多い順にソート\n",
    "        df=pd.DataFrame(tuples)\n",
    "        if topic_num < 10:\n",
    "            df.to_csv( './cleansing_data/result_iter10000/topic_100/topic'+'0'+str(topic_num)+str(filename), index=False )\n",
    "        else:\n",
    "            df.to_csv( './cleansing_data/result_iter10000/topic_100/topic'+str(topic_num)+str(filename), index=False )\n",
    "        topic_num+=1\n",
    "    print(\"END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_tag_lines=read_file('./cleansing_data/goodtags.csv')\n",
    "#good_tag_input=make_Coordinate(good_tag_lines)\n",
    "good_tag_input=make_Coordinate(good_tag_lines[0:50000])\n",
    "Coordinate_lines=read_file('./cleansing_data/goodCoords.csv')\n",
    "# good_Coordinate_input=make_Coordinate(Coordinate_lines)\n",
    "good_Coordinate_input=make_Coordinate(Coordinate_lines[0:50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3698\n",
      "6190\n"
     ]
    }
   ],
   "source": [
    "# モデルに入れる前に形式を合わせる必要がある\n",
    "tag_set=make_brandset(good_tag_lines[0:50000])\n",
    "# tag_set=make_brandset(good_tag_lines)\n",
    "tag_dict=make_dict(tag_set)\n",
    "brand_set=make_brandset(Coordinate_lines[0:50000])\n",
    "# brand_set=make_brandset(Coordinate_lines)\n",
    "brand_dict=make_dict(brand_set)\n",
    "tag_W=brand_to_dictnum(good_tag_input,tag_dict)\n",
    "Coordinate_W=brand_to_dictnum(good_Coordinate_input,brand_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nctm import NCTM\n",
    "W=Coordinate_W\n",
    "X=tag_W\n",
    "Vw = len(W)\n",
    "Vx = len(X)\n",
    "K = 100\n",
    "alpha = 0.1\n",
    "beta= 0.1\n",
    "gamma= 0.1\n",
    "eta = 1.0\n",
    "max_iter = 10000\n",
    "nctm = NCTM(K=K, alpha=alpha, beta=beta, gamma=gamma, eta=eta, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed widget Javascript is the wrong version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time:15341.912932872772\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "nctm.fit(W,X,Vw,Vx)\n",
    "elapsed_time = time.time() - start\n",
    "print(\"elapsed_time:{0}\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 改めて普通のLDAをやってみるのもあり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[314, 234, 241, 265, 231, 249, 243, 261, 219, 223, 238, 224, 253, 249, 231, 246, 248, 259, 238, 245, 212, 260, 237, 257, 265, 228, 203, 239, 258, 241, 231, 232, 274, 225, 273, 292, 237, 230, 233, 226, 238, 262, 208, 274, 257, 227, 293, 251, 293, 247, 295, 245, 229, 247, 247, 246, 230, 232, 217, 215, 241, 264, 239, 234, 241, 286, 246, 230, 253, 191, 240, 216, 211, 221, 243, 254, 239, 310, 203, 370, 259, 205, 216, 270, 241, 217, 235, 239, 224, 223, 222, 244, 239, 240, 209, 212, 267, 217, 225, 234]\n",
      "[884, 855, 845, 857, 831, 857, 845, 878, 897, 864, 855, 876, 837, 808, 826, 880, 829, 895, 887, 862, 803, 853, 888, 841, 850, 904, 878, 846, 826, 882, 841, 866, 853, 820, 866, 846, 833, 861, 846, 878, 878, 847, 875, 850, 843, 840, 849, 839, 843, 851, 877, 846, 841, 852, 818, 829, 841, 858, 837, 820, 832, 830, 778, 812, 850, 852, 828, 814, 830, 799, 870, 807, 878, 805, 864, 893, 846, 833, 838, 835, 861, 832, 869, 817, 805, 831, 919, 888, 886, 814, 858, 892, 899, 813, 811, 890, 844, 862, 843, 845]\n"
     ]
    }
   ],
   "source": [
    "brand_topic=brand_to_topic(good_Coordinate_input,nctm.Z)\n",
    "tag_topic=brand_to_topic(good_tag_input,nctm.Y)\n",
    "\n",
    "#topicごとにブランドとトピックの組をまとめる\n",
    "brand_topic_list=brand_topic_list_f(brand_topic,K)\n",
    "tag_topic_list=brand_topic_list_f(tag_topic,K)\n",
    "\n",
    "#トピックごとに出現ブランドのセットを作る\n",
    "t_setlist_brand=t_setlist_brand_f(brand_topic_list,K)\n",
    "t_setlist_tag=t_setlist_brand_f(tag_topic_list,K)\n",
    "\n",
    "# 各トピックごとのサイズの確認\n",
    "TopicBrandSize=[]\n",
    "TopicTagSize=[]\n",
    "index=[]\n",
    "for i in range(len(t_setlist_brand)):\n",
    "    TopicBrandSize.append(len(t_setlist_brand[i]))\n",
    "    TopicTagSize.append(len(t_setlist_tag[i]))\n",
    "    index.append(i)\n",
    "print(TopicBrandSize)\n",
    "print(TopicTagSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#セットを用いて出現回数をカウント\n",
    "count_topic_brand=count_topic_f(brand_topic_list,t_setlist_brand,K)\n",
    "count_topic_tag=count_topic_f(tag_topic_list,t_setlist_tag,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "#結果の書き込み\n",
    "import pandas as pd\n",
    "write_result('brands.csv',t_setlist_brand,count_topic_brand)\n",
    "write_result('tags.csv',t_setlist_tag,count_topic_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zukako",
   "language": "python",
   "name": "zukako"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
